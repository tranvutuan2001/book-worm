# AI Chat Application

A modern, minimalist chat application built with Next.js 14, TypeScript, Tailwind CSS, and Zod for schema validation. This app provides a clean interface for chatting with LLM services.

## Features

- ðŸŽ¨ **Modern UI**: Clean, simple interface with white and light purple theme
- ðŸ’¬ **Real-time Chat**: Interactive chat interface with message history
- âœ… **Type-Safe**: Built with TypeScript and Zod for runtime validation
- ðŸŽ¯ **Responsive Design**: Works seamlessly on desktop and mobile devices
- âš¡ **Next.js 14**: Built on the latest Next.js with App Router
- ðŸŽ­ **Tailwind CSS**: Utility-first styling for rapid development

## Tech Stack

- **Framework**: Next.js 14 (App Router)
- **Language**: TypeScript
- **Styling**: Tailwind CSS
- **Validation**: Zod
- **Package Manager**: npm

## Getting Started

First, run the development server:

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## Project Structure

```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â””â”€â”€ route.ts          # API endpoint for chat (placeholder)
â”‚   â”œâ”€â”€ globals.css                # Global styles with purple theme
â”‚   â”œâ”€â”€ layout.tsx                 # Root layout
â”‚   â””â”€â”€ page.tsx                   # Main chat page
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatHeader.tsx             # Header component
â”‚   â”œâ”€â”€ ChatInput.tsx              # Message input component
â”‚   â””â”€â”€ MessageBubble.tsx          # Message display component
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ api.ts                     # API client functions
â”‚   â””â”€â”€ schemas.ts                 # Zod schemas for validation
â””â”€â”€ package.json
```

## Backend Integration

The application includes placeholder API endpoints that you can connect to your LLM backend:

### API Endpoint: `/api/chat`

Located in `app/api/chat/route.ts`, this endpoint currently returns an echo response. To connect to your backend:

1. Replace the placeholder logic in `app/api/chat/route.ts`
2. Update the API call to point to your LLM service
3. Modify the response handling as needed

Example integration:

```typescript
// In app/api/chat/route.ts
const response = await fetch('YOUR_BACKEND_URL/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${process.env.API_KEY}`,
  },
  body: JSON.stringify({
    message: validatedData.message,
    conversationId: validatedData.conversationId,
  }),
});

const data = await response.json();
```

## Customization

### Theme Colors

The color scheme is defined in `app/globals.css`. You can customize the purple shades by modifying the CSS variables.

### Components

All UI components are in the `components/` directory and can be easily customized:

- `ChatHeader.tsx` - Modify the header text and styling
- `ChatInput.tsx` - Adjust input behavior and appearance
- `MessageBubble.tsx` - Change message bubble styling

## Validation Schemas

The app uses Zod for type-safe validation. Schemas are defined in `lib/schemas.ts`:

- `MessageSchema` - Validates message objects
- `ChatRequestSchema` - Validates API requests
- `ChatResponseSchema` - Validates API responses

## Build for Production

```bash
npm run build
npm start
```

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme).

Check out the [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

